{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76fbaf88-5952-47bf-a68c-85011e49b6de",
   "metadata": {},
   "source": [
    "# Building our First RAG bot - Skill: talk to Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c3b06-c8a0-45db-be9a-974c762ba4b8",
   "metadata": {},
   "source": [
    "We have now all the building blocks to build our first Bot that \"talks with my data\". These blocks are:\n",
    "\n",
    "1) A well indexed hybrid (text and vector) engine with my data in chunks -> Azure AI Search\n",
    "2) A good LLM python framework to build LLM Apps -> LangChain\n",
    "3) Quality OpenAI GPT models that understand language and follow instructions\n",
    "4) A persisten memory database -> CosmosDB\n",
    "\n",
    "We are missing just one thing: **Agents**.\n",
    "\n",
    "In this Notebook we introduce the concept of Agents and we use it to build or first RAG bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64f701d-5b9d-4c7c-b259-c2a515c75961",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import asyncio\n",
    "from typing import Dict, List\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.runnables import ConfigurableField, ConfigurableFieldSpec\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import  GetDocSearchResults_Tool\n",
    "from common.prompts import AGENT_DOCSEARCH_PROMPT\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4163af7-39d0-43b4-8dad-c13108d22a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33836104-822e-4846-8b81-0de8e24838f1",
   "metadata": {},
   "source": [
    "## Introducing: Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fc3d38-93f8-4a47-8125-d1bb9f529178",
   "metadata": {},
   "source": [
    "The implementation of Agents is inspired by two papers: the [MRKL Systems](https://arxiv.org/abs/2205.00445) paper (pronounced â€˜miracleâ€™ ðŸ˜‰) and the [ReAct](https://arxiv.org/abs/2210.03629) paper.\n",
    "\n",
    "Agents are a way to leverage the ability of LLMs to understand and act on prompts. In essence, an Agent is an LLM that has been given a very clever initial prompt. The prompt tells the LLM to break down the process of answering a complex query into a sequence of steps that are resolved one at a time.\n",
    "\n",
    "Agents become really cool when we combine them with â€˜expertsâ€™, introduced in the MRKL paper. Simple example: an Agent might not have the inherent capability to reliably perform mathematical calculations by itself. However, we can introduce an expert - in this case a calculator, an expert at mathematical calculations. Now, when we need to perform a calculation, the Agent can call in the expert rather than trying to predict the result itself. This is actually the concept behind [ChatGPT Pluggins](https://openai.com/blog/chatgpt-plugins).\n",
    "\n",
    "In our case, in order to solve the problem \"How do I build a smart bot that talks to my data\", we need this REACT/MRKL approach, in which we need to instruct the LLM that it needs to use 'experts/tools' in order to read/load/understand/interact with a any particular source of data.\n",
    "\n",
    "Let's create then an Agent that interact with the user and uses a Tool to get the information from the Search engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7999a06-aff0-4d21-8be7-fe56c70082a8",
   "metadata": {},
   "source": [
    "#### 1. We start first defining the Tool/Expert\n",
    "\n",
    "Tools are functions that an agent can invoke. If you don't give the agent access to a correct set of tools, it will never be able to accomplish the objectives you give it. If you don't describe the tools well, the agent won't know how to use them properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a862366b-ce9e-44f8-9610-84ec568653ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index1_name = \"srch-index-files\"\n",
    "index2_name = \"srch-index-csv\"\n",
    "index3_name = \"srch-index-books\"\n",
    "indexes = [index1_name, index2_name, index3_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077886c8-c5d0-481d-a5f9-f4becf60e0f9",
   "metadata": {},
   "source": [
    "We have to convert the Retreiver object into a Tool object (\"the expert\"). Check out the Tool `GetDocSearchResults_Tool` in `utils.py` and see how it is done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c6ca7-d93b-4961-b90a-08572cad78d8",
   "metadata": {},
   "source": [
    "Declare the tools the agent will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0fd3a0-527c-42e3-a092-46e03d33bd07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [GetDocSearchResults_Tool(indexes=indexes, k=10, reranker_th=1, sas_token=os.environ['BLOB_SAS_TOKEN'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ddf18-3f3c-44b4-8af5-1437973da010",
   "metadata": {},
   "source": [
    "#### 2. Define the LLM to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aaaf7f5-ef26-48d8-868d-b53aa4c4f9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COMPLETION_TOKENS = 1500\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT4oMINI_DEPLOYMENT_NAME\"], \n",
    "                      temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865755b-e4bb-468a-8dcc-4ac1999782b3",
   "metadata": {},
   "source": [
    "#### 3. Bind tools to the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61b209-1c1e-48ff-957e-1ec2e375ada4",
   "metadata": {},
   "source": [
    "Newer OpenAI models (1106 and newer) have been fine-tuned to detect when one or more function(s) should be called and respond with the inputs that should be passed to the function(s). In an API call, you can describe functions and have the model intelligently choose to output a JSON object containing arguments to call these functions. The goal of the OpenAI tools APIs is to more reliably return valid and useful function calls than what can be done using a generic text completion or chat API.\n",
    "\n",
    "OpenAI termed the capability to invoke a single function as **functions**, and the capability to invoke one or more functions as [**tools**](https://platform.openai.com/docs/guides/function-calling).\n",
    "\n",
    "> OpenAI API has deprecated functions in favor of tools. The difference between the two is that the tools API allows the model to request that multiple functions be invoked at once, which can reduce response times in some architectures. Itâ€™s recommended to use the tools agent for OpenAI models.\n",
    "\n",
    "Having an LLM call multiple tools at the same time can greatly speed up agents whether there are tasks that are assisted by doing so. Thankfully, OpenAI models versions 1106 and newer support parallel function calling, which we will need to make sure our smart bot is performant.\n",
    "\n",
    "##### **From now on and for the rest of the notebooks, we are going to use OpenAI tools API tool call our experts/tools**\n",
    "\n",
    "To pass in our tools to the agent, we just need to format them to the [OpenAI tool format](https://platform.openai.com/docs/api-reference/chat/create) and pass them to our model. (By bind-ing the functions, weâ€™re making sure that theyâ€™re passed in each time the model is invoked.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "856361f5-87b5-46f0-a0a6-ce3c1566ff48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bind (attach) the tools/functions we want on each LLM call\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Let's also add the option to configure in real time the model we want\n",
    "\n",
    "llm_with_tools = llm_with_tools.configurable_alternatives(\n",
    "    ConfigurableField(id=\"model\"),\n",
    "    default_key=\"gpt4omini\",\n",
    "    gpt4o=AzureChatOpenAI(deployment_name=os.environ[\"GPT4o_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c64bd-89ca-494e-8c01-f948f9a3e6a7",
   "metadata": {},
   "source": [
    "#### 4. Define the System Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30901f95-3bf9-4aaa-9eda-226edbf5ea00",
   "metadata": {},
   "source": [
    "Because OpenAI Function Calling is finetuned for tool usage, we hardly need any instructions on how to reason, or how to output format. We will just have two input variables: `question` and `agent_scratchpad`. The input variable `question` should be a string containing the user objective, and `agent_scratchpad` should be a sequence of messages that contains the previous agent tool invocations and the corresponding tool outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cac295-8be5-4803-8342-6d4e48cd2294",
   "metadata": {},
   "source": [
    "Get the prompt to use `AGENT_DOCSEARCH_PROMPT` - you can modify this in `prompts.py`! Check it out!\n",
    "It looks like this:\n",
    "\n",
    "```python\n",
    "AGENT_DOCSEARCH_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", CUSTOM_CHATBOT_PREFIX  + DOCSEARCH_PROMPT_TEXT),\n",
    "        MessagesPlaceholder(variable_name='history', optional=True),\n",
    "        (\"human\", \"{question}\"),\n",
    "        MessagesPlaceholder(variable_name='agent_scratchpad')\n",
    "    ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a44f8df6-a68e-4215-99f3-10119f796c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = AGENT_DOCSEARCH_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581ad422-c06b-434f-bff0-e2a3d6093932",
   "metadata": {},
   "source": [
    "#### 5. Create the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519b70c-007d-405c-9a81-18f58c5617be",
   "metadata": {},
   "source": [
    "The core idea of agents is to use a language model to choose a sequence of actions to take. In chains, a sequence of actions is hardcoded (in code). In agents, a language model is used as a reasoning engine to determine which actions to take and in which order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16be0ef1-dc72-49fa-8aa7-cdd2153ef8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(x[\"intermediate_steps\"]),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d9a8b-2a93-4250-b1dc-b124fa8c7ffa",
   "metadata": {},
   "source": [
    "Or , which is equivalent, LangChain has a class that does exactly the cell code above: `create_openai_tools_agent`\n",
    "\n",
    "```python\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "```\n",
    "\n",
    "**Important Note: Other models like Mistral Large or Command R+ won't work with the same OpenAI Tools API, so in order to create agents with these models, try using the ReAct type instead from langchain**. Like [THIS COHERE AGENT](https://python.langchain.com/docs/integrations/providers/cohere/#react-agent) for example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338336d9-a64a-4602-908a-742b418e4520",
   "metadata": {},
   "source": [
    "Create an agent executor by passing in the agent and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad6c156f-9a17-4daa-80de-70ce2f55063b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a017c-3b36-43ab-8633-78f4f005d166",
   "metadata": {},
   "source": [
    "Give it memory - since AgentExecutor is also a Runnable class, we do the same with did on Notebook 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c013314-afe6-4218-b179-d0f7312d2670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
    "    cosmos = CosmosDBChatMessageHistory(\n",
    "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "        session_id=session_id,\n",
    "        user_id=user_id\n",
    "        )\n",
    "\n",
    "    # prepare the cosmosdb instance\n",
    "    cosmos.prepare_cosmos()\n",
    "    return cosmos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df017f-3ab7-4943-adc1-3477badf3d3e",
   "metadata": {},
   "source": [
    "Because cosmosDB needs two fields (an id and a partition), and RunnableWithMessageHistory takes by default only one identifier for memory (session_id), we need to use `history_factory_config` parameter and define the multiple keys for the memory class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf93758f-da3b-48fb-9882-91fe327b1751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "userid_spec = ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        )\n",
    "session_id = ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d1aaa6-efca-4512-b680-896dae39a359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[userid_spec,session_id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05c6b489-3db9-4965-9eae-ed2790e62bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'session931', 'user_id': 'user627'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure the session id and user id\n",
    "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
    "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
    "\n",
    "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3295c54e-a5e2-46f6-99fc-6f76453a877d",
   "metadata": {},
   "source": [
    "#### 6.Run the Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ac81763-6bcc-4408-9daf-d047a0e2cb08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 320 ms, sys: 19.7 ms, total: 340 ms\n",
      "Wall time: 5.42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'How Chandler proposes to Monica?',\n",
       " 'history': [],\n",
       " 'output': 'Chandler Bing\\'s proposal to Monica Geller is a memorable moment in the series *Friends*. It occurs in Season 6, Episode 24, titled \"The One with the Proposal.\" Hereâ€™s how it unfolds:\\n\\n1. **Setting the Scene**: Chandler decides to propose to Monica in a romantic manner. He takes her to a restaurant, intending to make the moment special by ordering her favorite champagne.\\n\\n2. **The Proposal**: As they sit down, Chandler starts to express his feelings. He realizes that what matters most is not the setting or the words, but the love he feels for Monica. He says:\\n   > \"I thought that it mattered what I said or where I said it. Then I realized the only thing that matters is that you make me happier than I ever thought I could be. And if you\\'ll let me, I will spend the rest of my life trying to make you feel the same way. Monica, will you marry me?\"\\n\\n3. **Monica\\'s Response**: Overwhelmed with joy, Monica replies:\\n   > \"Yes.\"\\n\\n4. **Celebration**: After the proposal, they celebrate their engagement with their friends, who are eager to know the news.\\n\\nThis heartfelt moment encapsulates the essence of their relationship, showcasing Chandler\\'s growth and commitment to Monica, and highlights the show\\'s blend of humor and emotion [[6]](https://blobstorageuq7x4ufcftcpm.blob.core.windows.net/friends/s06/e24/c01.txt?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-10-03T01:44:00Z&st=2024-10-02T17:44:00Z&spr=https&sig=0eJm6CaaACeHGfgKGIXE163moq7X0Mu6tbZcCU0MHkA%3D).'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "agent_with_chat_history.invoke({\"question\": \"How Chandler proposes to Monica?\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb3fca7e-33a1-40f1-afb0-dee441a1d1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## What are Markov Chains?\n",
       "\n",
       "**Markov Chains** are mathematical models that describe systems that transition from one state to another within a finite or countable number of states. The key characteristic of a Markov Chain is the **Markov property**, which states that the future state of the system depends only on the current state and not on the sequence of events that preceded it. This property allows for the simplification of complex systems into manageable models.\n",
       "\n",
       "### Key Components:\n",
       "1. **States**: The possible situations in which the system can exist.\n",
       "2. **Transition Probabilities**: The probabilities of moving from one state to another.\n",
       "3. **Transition Matrix**: A matrix that represents the probabilities of transitioning from each state to every other state.\n",
       "\n",
       "Markov Chains can be classified into:\n",
       "- **Discrete-time Markov Chains**: Where transitions occur at fixed time intervals.\n",
       "- **Continuous-time Markov Chains**: Where transitions can occur at any time.\n",
       "\n",
       "### Applications in Medicine\n",
       "Markov Chains have various applications in the medical field, particularly in modeling disease progression, treatment outcomes, and healthcare decision-making.\n",
       "\n",
       "1. **Disease Spread Modeling**: Markov Chains can be used to model the spread of infectious diseases, such as COVID-19. For instance, a nonlinear Markov chain model was proposed to analyze the behavior of the COVID-19 pandemic, estimating daily new cases and examining correlations with daily deaths [[8]](http://medrxiv.org/cgi/content/short/2020.04.21.20073668v1?rss=1?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-10-03T01:44:00Z&st=2024-10-02T17:44:00Z&spr=https&sig=0eJm6CaaACeHGfgKGIXE163moq7X0Mu6tbZcCU0MHkA%3D).\n",
       "\n",
       "2. **Epidemiological Simulation**: A discrete-time Markov chain simulator has been developed to model the dynamics of epidemics, allowing researchers to test different control algorithms [[9]](https://doi.org/10.1109/embc.2016.7591271).\n",
       "\n",
       "3. **Cost-Effectiveness Analysis**: Markov models are employed to assess the cost-effectiveness of medical treatments. For example, a study used a Markov model to evaluate the cost-effectiveness of extracorporeal cardiopulmonary resuscitation (ECPR) for cardiac arrest patients [[10]](https://doi.org/10.1016/j.resuscitation.2019.08.024).\n",
       "\n",
       "4. **Airborne Disease Transmission**: Markov chains have been integrated with computational fluid dynamics to predict airborne disease transmission in enclosed environments, providing valuable insights for reducing infection risks [[6]](https://doi.org/10.1111/ina.12056).\n",
       "\n",
       "These applications illustrate the versatility of Markov Chains in addressing complex medical problems, enhancing our understanding of disease dynamics, and informing healthcare decisions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(agent_with_chat_history.invoke(\n",
    "    {\"question\": \"What are markov chains and is there an application in medicine?\"}, \n",
    "    config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c430c456-f390-4319-a3b1-bee19da130cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Markov chains have been effectively utilized in modeling the spread of viruses, particularly in understanding how infectious diseases propagate through populations. Here are some key insights into their application:\n",
       "\n",
       "### 1. Spatial Markov Chain Models\n",
       "A **Spatial Markov Chain model** represents the spread of viruses by connecting nodes that symbolize individuals (e.g., humans). The edges between these nodes signify interpersonal relationships. The likelihood of virus transmission is influenced by the intensity of contact between individuals, and the transfer of infection is determined by chance. This model can be extended to simulate various lockdown scenarios, helping to assess the impact of social distancing measures on virus spread [[1]](https://arxiv.org/pdf/2004.05635v1.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-10-03T01:44:00Z&st=2024-10-02T17:44:00Z&spr=https&sig=0eJm6CaaACeHGfgKGIXE163moq7X0Mu6tbZcCU0MHkA%3D).\n",
       "\n",
       "### 2. Continuous-Time Markov Chain (CTMC) Models\n",
       "CTMC models have been applied to study the emergence and re-emergence of infectious diseases. These models account for different groups within a population, such as superspreadersâ€”individuals who infect a disproportionately large number of others. The transmission rates can vary based on whether the host is infectious or susceptible. This approach allows researchers to estimate the probability of minor or major epidemics based on initial conditions [[2]](https://doi.org/10.1080/17513758.2018.1538462; https://www.ncbi.nlm.nih.gov/pubmed/30381000/?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-10-03T01:44:00Z&st=2024-10-02T17:44:00Z&spr=https&sig=0eJm6CaaACeHGfgKGIXE163moq7X0Mu6tbZcCU0MHkA%3D).\n",
       "\n",
       "### 3. Nonlinear Markov Chain Models\n",
       "During the COVID-19 pandemic, nonlinear Markov chain models were developed to analyze the spread of the virus using data from various countries. These models estimate daily new cases and examine correlations between new cases and deaths, providing valuable insights into epidemic trends [[3]](http://medrxiv.org/cgi/content/short/2020.04.21.20073668v1?rss=1?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-10-03T01:44:00Z&st=2024-10-02T17:44:00Z&spr=https&sig=0eJm6CaaACeHGfgKGIXE163moq7X0Mu6tbZcCU0MHkA%3D).\n",
       "\n",
       "### 4. Parametric Time-Varying Markov Processes\n",
       "These processes help estimate model parameters and approximate unobserved counts of infected, recovered, and immunized individuals based on daily reported cases and deaths. This approach is particularly useful in scenarios where many infected individuals show no symptoms, complicating the tracking of the virus's spread [[4]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7090511/?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-10-03T01:44:00Z&st=2024-10-02T17:44:00Z&spr=https&sig=0eJm6CaaACeHGfgKGIXE163moq7X0Mu6tbZcCU0MHkA%3D).\n",
       "\n",
       "### 5. Non-Markovian Models\n",
       "Recent studies suggest that the epidemiological parameters for COVID-19 do not always follow exponential distributions, leading to the development of **non-Markovian models**. These models aim to capture more accurately the complex dynamics of virus transmission, especially in the absence of strict control measures [[5]](https://doi.org/10.1101/2020.02.07.20021139?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-10-03T01:44:00Z&st=2024-10-02T17:44:00Z&spr=https&sig=0eJm6CaaACeHGfgKGIXE163moq7X0Mu6tbZcCU0MHkA%3D).\n",
       "\n",
       "### Conclusion\n",
       "Markov chains, both in their standard and nonlinear forms, provide powerful tools for modeling the spread of viruses. They help researchers understand the dynamics of infectious diseases, estimate the potential for outbreaks, and evaluate the effectiveness of interventions. The evolution of these models continues to adapt to the complexities of real-world scenarios, particularly in light of new infectious diseases like COVID-19."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(agent_with_chat_history.invoke(\n",
    "        {\"question\": \"Interesting, Tell me more about the use of markov chains, specifically in the spread of viruses\"},\n",
    "        config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fd54f71-03c9-4332-885b-0d1df942fa88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You're welcome! If you have any questions or need assistance with anything else, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61.9 ms, sys: 10.3 ms, total: 72.2 ms\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "printmd(agent_with_chat_history.invoke({\"question\": \"Thhank you!\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41787714-73fd-4336-85f2-bec3abb41eda",
   "metadata": {},
   "source": [
    "### Let's add more things we have learned so far: dynamic LLM selection of GPT4o and asyncronous streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1511d2c3-97fe-4232-a560-014d0f157008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm_with_tools.with_config(configurable={\"model\": \"gpt4o\"}), tools, prompt) # We select now GPT-4o\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
    "agent_with_chat_history = RunnableWithMessageHistory(agent_executor,get_session_history,input_messages_key=\"question\", \n",
    "                                                     history_messages_key=\"history\", history_factory_config=[userid_spec,session_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec5b32-6017-44b9-97e7-34ba3695e688",
   "metadata": {},
   "source": [
    "In prior notebooks with use the function `.stream()` of the runnable in order to stream the tokens. However if you need to stream individual tokens from the agent or surface steps occuring within tools, you would need to use a combination of `Callbacks` and `.astream()` OR the new `astream_events` API (beta).\n",
    "\n",
    "Letâ€™s use here the astream_events API to stream the following events:\n",
    "\n",
    "    Agent Start with inputs\n",
    "    Tool Start with inputs\n",
    "    Tool End with outputs\n",
    "    Stream the agent final anwer token by token\n",
    "    Agent End with outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9600a35e-8d2e-43d0-a334-092b2e8b832c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUESTION = \"Tell me more about chandler proposing to monica, search again multiple times and provide a deeper explanation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3808fa33-05bb-4f5d-9ab9-7159f6db62a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent: AgentExecutor\n",
      "--\n",
      "Starting tool: docsearch with inputs: {'query': 'Chandler proposes to Monica scene'}\n",
      "--\n",
      "Starting tool: docsearch with inputs: {'query': 'Chandler Bing proposal to Monica Geller details'}\n",
      "--\n",
      "Starting tool: docsearch with inputs: {'query': 'Friends Chandler Monica proposal episode'}\n",
      "Done tool: docsearch\n",
      "--\n",
      "Done tool: docsearch\n",
      "--\n",
      "Done tool: docsearch\n",
      "--\n",
      "Chandler Bing's proposal to Monica Geller is a pivotal moment in the series *Friends*, and it unfolds with a mix of romance, humor, and heartfelt emotion.\n",
      "\n",
      "### The Build-Up\n",
      "\n",
      "Chandler initially plans to propose to Monica in a traditional manner by taking her to her favorite restaurant. He intends to order her favorite champagne, which she knows is expensive, and then propose a toast that turns into a marriage proposal [[4]](https://blobstorageuq7x4ufcftcpm.blob.core.windows.net/friends/s06/e24/c01.txt?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-10-03T01:44:00Z&st=2024-10-02T17:44:00Z&spr=https&sig=0eJm6CaaACeHGfgKGIXE163moq7X0Mu6tbZcCU0MHkA%3D).\n",
      "\n",
      "### The Proposal\n",
      "\n",
      "The proposal takes place in Season 6, Episode 25, titled \"The One with the Proposal.\" Monica and Chandler's relationship faces some challenges leading up to the proposal. Monica is upset and leaves, leading Chandler to worry that he has lost her. However, when he returns home, he finds Monica waiting for him in their apartment, surrounded by candles.\n",
      "\n",
      "Monica starts to propose to Chandler, but becomes emotional and struggles to find the words, saying:\n",
      "> \"In all my life... I never thought I would be so lucky as to fall in love with my best... my best... There's a reason why girls don't do this!\" \n",
      "\n",
      "Chandler then takes over, expressing his love and commitment to her:\n",
      "> \"I thought that it mattered what I said or where I said it. Then I realized the only thing that matters is that you, you make me happier than I ever thought I could be. And if you'll let me, I will spend the rest of my life trying to make you feel the same way. Monica, will you marry me?\"\n",
      "\n",
      "Monica, overwhelmed with joy, responds with a simple but heartfelt \"Yes\" [[3]](https://blobstorageuq7x4ufcftcpm.blob.core.windows.net/friends/s06/e25/c12.txt?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-10-03T01:44:00Z&st=2024-10-02T17:44:00Z&spr=https&sig=0eJm6CaaACeHGfgKGIXE163moq7X0Mu6tbZcCU0MHkA%3D).\n",
      "\n",
      "### The Celebration\n",
      "\n",
      "Following the proposal, their friends are invited in to celebrate the engagement. The moment is filled with joy and laughter, marking a significant milestone in the series. Rachel even comments on how it's the least jealous she's ever been, highlighting the genuine happiness shared among the friends [[3]](https://blobstorageuq7x4ufcftcpm.blob.core.windows.net/friends/s06/e25/c12.txt?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2025-10-03T01:44:00Z&st=2024-10-02T17:44:00Z&spr=https&sig=0eJm6CaaACeHGfgKGIXE163moq7X0Mu6tbZcCU0MHkA%3D).\n",
      "\n",
      "Chandler's proposal is a culmination of his growth as a character and his deep love for Monica, making it one of the most memorable and beloved scenes in *Friends*.\n",
      "--\n",
      "Done agent: AgentExecutor\n"
     ]
    }
   ],
   "source": [
    "async for event in agent_with_chat_history.astream_events(\n",
    "    {\"question\": QUESTION}, config=config, version=\"v1\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (event[\"name\"] == \"AgentExecutor\"):\n",
    "            print( f\"Starting agent: {event['name']}\")\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (event[\"name\"] == \"AgentExecutor\"):  \n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(f\"Done agent: {event['name']}\")\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        # Empty content in the context of OpenAI means that the model is asking for a tool to be invoked.\n",
    "        # So we only print non-empty content\n",
    "        if content:\n",
    "            print(content, end=\"\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\")\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        # print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec64bf-fe24-42fc-8dde-4d478f0af21e",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We just built our first RAG BOT!.\n",
    "\n",
    "- We learned that **Agents + Tools are the best way to go about building Bots**. <br>\n",
    "- We converted the Azure Search retriever into a Tool using the function `GetDocSearchResults_Tool` in `utils.py`\n",
    "- We learned about the events API, one way to stream the answer from agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56306506-d53d-4d43-93e2-a9300ed2a3ee",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "\n",
    "Now that we have a bot with one skill (Document Search), let's build more skills!. In the next Notebook, we are going to build an agent that can understand tabular data in csv file and can execute python commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db8477-5d1a-4587-a766-3933a59ce54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
